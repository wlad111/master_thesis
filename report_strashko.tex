\documentclass[specialist,
               substylefile = spbu.rtx,
               subf,href,colorlinks=true, 12pt]{disser}

\usepackage[a4paper,
            mag=1000, includefoot,
            left=3cm, right=1.5cm, top=2cm, bottom=2cm, headsep=1cm, footskip=1cm]{geometry}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}


\usepackage[linesnumbered,boxed]{algorithm2e}
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}

\usepackage{float}

\floatname{algorithm}{Listing}

\newtheorem{definition}{Определение}
\newtheorem{theorem}{Теорема}

\DeclareMathOperator{\score}{Score}
\DeclareMathOperator{\cov}{cov}

\ifpdf\usepackage{epstopdf}\fi

% Точка с запятой в качестве разделителя между номерами цитирований
%\setcitestyle{semicolon}

% Использовать полужирное начертание для векторов
\let\vec=\mathbf

% Включать подсекции в оглавление
\setcounter{tocdepth}{2}

\graphicspath{{fig/}}

%----------------------------------------------------------------
\begin{document}

%
% Титульный лист на русском языке
%

% Название организации
\institution{%
    Санкт-Петербургский государственный университет
}

\title{Выпускная квалификационная работа}

% Тема
\topic{\normalfont\scshape%
    Разработка программного комплекса методов оценивания малых вероятностей}

% Автор
\author{\textsc{Страшко} Владислав Алексеевич}

\group{%
	Уровень образования: магистратура\\
	Направление 01.04.02 <<Прикладная математика и информатика>>\\
	Основная образовательная программа ВМ.5688.2018 <<Прикладная математика и информатика>> \\
	Профессиональная траектория <<Статистическое моделирование>>
}

% Научный руководитель
\sa       {А.\,И.~Коробейников}
\sastatus {к.\,ф.-м.\,н., доцент}

% Рецензент
\rev      {А.\,А.~Сергушичев}
\revstatus{Доцент, Университет ИТМО\\
	к.\,ф.-м.\,н., доцент}

% Город и год
\city{Санкт-Петербург}
\date{\number\year}

\maketitle

\tableofcontents

\intro
Предметом исследования данной работы является оценка вероятностей редких событий. Обычно задача имеет простую постановку: оценить $ P (\xi \in A) $ для некоторой случайной величины с известным нам распределением и некоторого множества $ A $. При этом, как правило, интерес представляют такие множества $ A $, для которых данная вероятность близка к нулю. Наивное решение такой задачи являет собой интегрирование по методу Монте-Карло, но при действительно малых вероятностях моделирование нужного распределения становится весьма трудоёмкой задачей.  При этом оценки, полученные по независимой выборке, как правило, обладают большой дисперсией.  Существуют различные методы уменьшения дисперсии оценки по методу Монте-Карло. Например, одним из них является метод существенной выборки, который позволяет получить интересующую оценку на основе выборки из некоторого специального распределения. Однако моделирование выборки из вообще говоря произвольного распределения --- непростая задача. В данной работе рассмотрен метод Монте-Карло по схеме марковской цепи. Его идея состоит в получении оценок Монте-Карло не по независимой выборке, а по траектории некоторой марковской цепи. Мы рассмотрим различные алгоритмы, которые позволяют моделировать марковские цепи с заранее заданным инвариантным распределением, на основе траектории которых можно строить оценки. Оказывается, что класс марковских цепей, для которых оценки имеют состоятельность и асимптотическую нормальность, весьма широк. Большинство из таких алгоритмов так или иначе основаны на моделировании по методу Метрополиса-Гастингса \cite{liang2011advanced}. Это очень простой в реализации и в то же время гибкий алгоритм, к тому же имеющий множество обобщений и адаптаций под различные задачи. Также очень часто для эффективного моделирования редких состояний некоторой случайной величины важно правильно подобрать плотность для моделирования существенной выборки. Алгоритм Ванга-Ландау решает (\cite{iba2014multicanonical}) эту задачу. Это адаптивный алгоритм построения плотности некоторого специального вида, при помощи которой можно получить хорошие (в смысле дисперсии) оценки по методу Монте-Карло. Кроме того, весьма важно оценивать качество получаемых оценок, а также уметь строить для них доверительные интервалы. Для этого нужно оценивать дисперсию. В данной работе мы рассмотрим методы оценки дисперсии вдоль траектории марковской цепи. Таким образом, исходная задача разбивается на несколько последовательных подзадач, для каждой из которых рассматриваются известные алгоритмы. 

Также мы увидим, что многие задачи оценивания вероятности формулируются некоторым общим образом, поэтому в данной работе рассматривается общий подход к решению задачи и предлагается небольшой фреймворк, предоставляющий подходящие инструменты.

Что касается непосредственно реализации, то в этом плане тоже возникает ряд проблем: есть много готовых решений, связанных с моделированием марковских цепей, но задача, рассматриваемая в этой работе имеет определённую специфику: пространство состояний дискретное и иногда очень большое. Поэтому хранение в явном виде пространства состояний неприемлемо. Это сразу делает почти все готовые решения неприменимыми для нашего случая. Поэтому в данной работе мы представляем расширенный вариант библиотеки PyMC3, который позволяет моделировать произвольные случайные объекты в дискретном пространстве состояний и на его основе получаем реализацию библиотеки для оценивания вероятностей редких событий. 

В Главе \ref{ch:theory} изложены необходимые теоретические факты, а также некоторые алгоритмы. 

Глава \ref{ch:strings} посвящена задаче вычисления вероятности максимального совпадения строк фиксированной длины над некоторым конечным алфавитом, причем ответ можно вычислить явно. Мы протестируем для этой задачи рассматриваемые в данной работе методы. В этом семестре был рассмотрен алгоритм параллельного темпериррования,  а также получены оценки по этому методу. Кроме того, добавлены графики, демонстрирующие поведение траекторий на бесконечности.

Глава \ref{ch:implementation} посвящена непосредственно реализации библиотеки. На данный момент проведён обзор существующих решений в рамках методов Монте-Карло по марковской цепи, таких как Stan, PyMC3. Кроме того, там рассматривается расширение библиотеки PyMC3, а также на его базе реализован пользовательский интерфейс, содержащий моделирование траектории, вычисление вероятности, вычисление дсиперсии и построение доверительного интервала После этого был воспроизведен пример из главы \ref{ch:strings} с использованием новых инструментов.







\chapter{Вспомогательные факты}
\label{ch:theory}
\section{Постановка задачи}

Для начала формализуем исследуемую задачу. Пусть задано вероятностное пространство $ (\Omega, \mathcal{F}, P)  $ и на нем определена случайная величина $ \xi $, принимающая значения в некотором пространстве $ \mathcal{X} $. При этом будем считать, что распределение $ \mathcal{P} $ этой случайной величины нам заранее известно. Далее, пусть задано некоторое множество $ A $. Задача состоит в вычислении $ P(\xi \in A) $. Известно, что  $$ P(\xi \in A) = \mathbb{E} \left[  \mathbb{I}_{A} (\xi)\right] = \int_{X} \mathbb{I}_{A} (x) \mathcal{P}(dx), $$ 
где  $ \mathbb{I}_{A} (x) $ --- индикатор множества $ A $. Далее мы рассмотрим различные методы оценивания этой величины.
\section{Интегрирование методом Монте-Карло}
Пусть  $ \nu $ --- вероятностная мера, заданная на борелевской $ \sigma $-алгебре $ \mathcal{B} $ подмножеств $ \mathcal{X} \subseteq \mathbb{R}^d $, и предположим, что нужно вычислить  
\begin{equation} \label{MC}
	\mathbb{E}_\nu \left[ h(\xi) \right] = \int_{\mathcal{X}} h(x)\nu(dx),
\end{equation}
где $ h(x) $ --- измеримая функция. Если $ \nu $ имеет плотность $ f(x) $ относительно меры Лебега, то \eqref{MC} принимает вид
\begin{equation*}
	\mathbb{E}_f \left[ h(\xi) \right] = \int_{\mathcal{X}} h(x) f(x)dx.
\end{equation*}
Теперь предположим, что у нас есть $ X_1, \ldots, X_n $ --- выборка из распределения $ \nu $. Тогда оценкой величины \eqref{MC} по методу Монте-Карло будет
\begin{equation}\label{MC-est}
	\bar{h}_n = \dfrac{1}{n} \sum_{i = 1}^{n} h(X_i).
\end{equation}
Оценка \eqref{MC-est} является состоятельной по закону больших чисел. В частности, для оценки $ P(\xi \in A) $ в качестве $ h(x) $ возьмём $ \mathbb{I}_A (x) $. Тогда оценкой будет 
\begin{equation}\label{MC-prob-est}
	\bar{h}_n = \dfrac{1}{n} \sum_{i = 1}^{n} \mathbb{I}_A (X_i).
\end{equation}
\subsection{Оценка при помощи существенной выборки}
Чтобы получить оценку величины \eqref{MC}, не обязательно иметь выборку из распределения $ \nu. $ Рассмотрим равенство
\begin{equation*} 
	\mathbb{E}_f \left[ h(\xi) \right] = \int_{\mathcal{X}} h(x)f(x)dx = \int_{\mathcal{X}} h(x) \dfrac{f(x)}{g(x)} g(x) dx = \mathbb{E}_g \left[\dfrac{h(\xi) f(\xi)}{g(\xi)}\right],
\end{equation*} 
и потребуем, чтобы из $ g(x) = 0 $, следовало $ f(x) = 0$. Тогда оценка 
\begin{equation}\label{MC-importance}
	\tilde{h}_n = \dfrac{1}{n} \sum_{i = 1}^{n} h(X_i) \dfrac{f(X_i)}{g(X_i)}
\end{equation}
будет оценкой интеграла \eqref{MC} по методу существенной выборки. Здесь $ X_1, \ldots, X_n $ --- выборка из распределения с плотностью $ g(x) $. При правильном подборе $ g(x) $ оценки по существенной выборке обладают меньшей дисперсией. Действительно, если подобрать плотность $ g(X_i) \propto h(X_i)f(X_i), $ то оценка будет близка к константе, и, соответственно будет обладать малой дисперсией.

\section{Метод Монте-Карло по схеме марковской цепи}

Иногда получить независимую выборку из некоторого распределения $ \pi $ не представляется возможным. В таком случае можно воспользоваться последовательностью зависимых величин $ \left\lbrace  X_i \right\rbrace  $. Одним классов таких последовательностей являются марковские цепи.

\subsection{Марковские цепи}

Мы приведём здесь основные определения и теоретические результаты относительно марковских цепей, которые пригодятся в рамках данной работы. Более подробно теория изложена в \cite{liang2011advanced}.
\begin{definition}
Марковской цепью называется последовательность случайных величин $ \left\lbrace  X_i: i = 0, 1, 2, \ldots \right\rbrace  $ такая, что для любого измеримого множества $ A \in \mathcal{X}$ выполняется $ P(X_{t+1} \in A | X_0 = x_0, \ldots, X_t = x_t) = P(X_{t+1} \in A | X_t = x_t)$ для $ \mathcal{P}_{X_0, \ldots, X_t} $-почти всех $ (x_0, \ldots, x_t) $ для $ t \geq 0 $. Здесь $ \mathcal{P}_{X_0, \ldots, X_t} $ --- совместное распределение величин $ X_0, \ldots, X_t $.
\end{definition}
Чтобы обращаться как с дискретными, так и с абсолютно непрерывными распределениями будем обозначать  $ \pi(dx) $ вероятностную меру, заданную на $ (\mathcal{X}, \mathcal{B}_{\mathcal{X}}) $. Для абсолютно непрерывной случайной величины $ X $ обозначим $ f(x) $ её плотность --- производную Радона-Никодима $ \pi(dx) $ относительно меры Лебега. В дискретном случае $ f(x) $ --- это производная Радона-Никодима относительно считающей меры. Обозначим $ P_t(dx) $ --- распределение $ X_t $. Пусть задано начальное распределение по состояниям $ P_0(dx) $. Также будем называть \textit{переходным ядром} $ P_t(x, dx) $ условное распределение $ X_{t+1} $ при условии $ X_t = x $. Данные распределения связаны между собой соотношением
\begin{equation*}
P_{t+1} (dy) = \int_{\mathcal{X}} P_t(dx) P_t(x, dy).
\end{equation*}
В рамках данной работы мы будем рассматривать только однородные по времени марковские цепи --- такие, что переходное ядро не зависит от номера состояния: для любого $ t > 0 $ выполнено
\begin{equation*}
	P_t (x, dy) = P(x, dy).
\end{equation*}
Это означает, что марковская цепь <<эволюционирует>>  по правилу
\begin{equation*}
	P_{t+1} (dy) = \int_{\mathcal{X}} P_t(dx) P(x, dy).
\end{equation*}
Таким образом, $ P_t (dx) $ определяется единственным образом начальным распределением и переходным ядром $ P(x, dy) $. Далее будем обозначать $ P^n (x, \cdot) $  условное распределение $ X_{n}  $ при условии $ X_0 = x $.
\begin{definition}
	Инвариантное распределение марковской цепи --- это такое распределение $ \pi(dx) $, для которого выполняется 
	\begin{equation} \label{balance-cond}
		\pi(dy) = \int_{\mathcal{X}} \pi(dx) P(x, dy),
	\end{equation}
	где $ P(x, dy) $ --- ядро перехода.	Также говорят, что в таком случае $ \pi $ и $ P(x, dy) $ удовлетворяют условию баланса.
	
\end{definition}
Например, если марковская цепь удовлетворяет условию $ P_{t + 1}(dx) = P_t (dx) = \pi(dx) $, то условие баланса будет выполнено. Тогда если $ X_t \sim \pi $, то и $ X_{t + 1} $ (вообще говоря, зависимая от $ X_t $ величина) будет иметь распределение $ \pi $. 
\begin{definition}
	Распределение $ \pi(dx) $ называется стационарным для марковской цепи, если соотношение	
	\begin{equation*}
		\lim_{t \rightarrow \infty} P(X_t \in A | X_0 = x) = \pi(A)
	\end{equation*}
	 для $ \pi $-почти всех $ x $ сохраняется для любого измеримого множества $ A $.
\end{definition}
\begin{definition}
	Будем называть марковскую цепь $ \pi $-неприводимой, если для любого начального состояния и для любого $ A \in \mathcal{B}_{\mathcal{X}} $ такого, что $ \pi(A) > 0 $, выполнено $ P(X_t \in~A) >~0 $ для некоторого $ t $.
\end{definition}
\begin{definition}
	$ \pi $-Неприводимая марковская цепь называется $ \pi $-периодической, если существует целое число $ d \geq 2 $ и последовательность $ \lbrace A_0, A_1, \ldots, A_{d-1} \rbrace $ непустых множеств из $ \mathcal{B}_{\mathcal{X}} $, таких что для всех $ i = 0, \ldots, d - 1 $ и всех $ x \in A_i $ выполнено
	\begin{equation*}
		P(x, A_j) = 1
	\end{equation*}
	для $j = i + 1 \mod d$.	В противном случае, она называется апериодической.
\end{definition}
Будем говорить, что события $ \lbrace A_i \rbrace $ случаются бесконечно часто и обозначать это как $ \lbrace A_n $ б.ч.$ \rbrace$, если $ P \left(\sum_i \mathbb{I}_{A_i} = \infty \right) = 1 $.
\begin{definition} 
	(a) Марковская цепь с инвариантным распределением $ \pi $ является рекуррентной, если для любого $ B $, такого что $ \pi(B) > 0 $, выполняется условие $$ P(X_n \in ~B \text{б.ч.} | X_0 = x) > 0 $$ для всех $ x $ и  
	$$ P(X_n \in B \text{ б.ч.} | X_0 = x) = 1 $$ для $ \pi $-почти всех $ x $.\\
	(b) Марковская цепь с инвариантным распределением $ \pi $ является Харрис-рекуррентной, если для любого $ B $, такого что $ \pi(B) > 0 $,  
	\begin{equation*}
		P(X_n \in B \text{ б.ч.} | X_0 = x) = 1
	\end{equation*}  
	для всех $ x $.
\end{definition}
\begin{definition}
		(a) Марковская цепь называется эргодической, если она является Харрис-рекуррентной и $ \pi $-апериодической.\\
	    (b) Марковская цепь с инвариантным распределением $ \pi $ обладает свойством геометрической эргодичности, если существует неотрицательная вещественнозначная функция $ M, $ для которой выполняется $ E[|M(X)|] < \infty $, и положительная константа $ r < 1 $ такая что 
		\begin{equation*}
			|| P^n(x, \cdot) - \pi || \leq M(x) r^n 
		\end{equation*}
		для всех x. 
		
		(c) Марковская цепь (b) равномерно эргодическая, если существует константа $ M $ и $0 < r < 1 $ такие что 
		\begin{equation*}
		|| P^n(x, \cdot) - \pi || \leq M r^n.
		\end{equation*}
		Здесь $ ||\cdot|| $ --- расстояние по вариации:
		\begin{equation*}
			|| \lambda || = \sup_{A \in \mathcal{X}} \lambda (A) - \inf_{A \in \mathcal{X}} \lambda(A)	
		\end{equation*}
\end{definition}
\begin{definition}
	Марковская цепь с переходным ядром $ P(x, dy) $ и инвариантным распределением $ \pi(dx) $ удовлетворяет уравнению детального баланса, если 
	\begin{equation} \label{detailed-balance}
		\int_{B} \int_{A} \pi(dx) P(x, dy)  = \int_{A} \int_{B} \pi(dy) P(y, dx)
	\end{equation}
	Для любых $ A, B \in \mathcal{B}_\mathcal{X}. $ Такая цепь также называется реверсивной.

\end{definition}
Можно показать, что из условия детального баланса вытекает условие баланса \eqref{balance-cond}.


\begin{theorem}[\cite{liang2011advanced}] \label{th:mc}
	Пусть марковская цепь с переходным ядром является $ \pi $-неприводимой и $ \pi $-инвариантной. Тогда она является рекуррентной и $ \pi $ --- её единственное инвариантное распределение. Если она при этом апериодическая, то для $ \pi $-почти всех выполнено
	
	\begin{equation*}
		|| P^n (x, \cdot) - \pi || \xrightarrow[]{n \rightarrow +\infty} 0.
	\end{equation*}
	
\end{theorem}
Другими словами, этот результат означает, что существует единственное стационарное распределение и оно совпадает с единственным инвариантным распределением. Также для марковских цепей есть аналог усиленного закона больших чисел. Справедлива следующая теорема.

\begin{theorem}[\cite{liang2011advanced}] \label{th:mc-lln}
	Пусть $ X_n $ эргодическая со стационарным распределением $ \pi $, а $ h(x) $ вещественнозначная и $ \mathbb{E}_\pi \left[ |h(X)| \right] < +\infty $. Тогда для любого начального распределения $ \bar{h}_n \rightarrow \mathbb{E}_\pi \left[ h(X) \right] $ почти наверное.
\end{theorem}

Основная идея построения марковских цепей для приближения \eqref{MC} состоит в том, чтобы построить $ P(x, dy) $ с инвариантным распределением $ \nu(dx) $. Как показано выше, при определённых условиях оно будет совпадать со стационарным распределением. При этом по Теореме \ref{th:mc-lln} будет иметь место состоятельность интересующей нас оценки. Далее рассмотрим алгоритм, позволяющий построить такую марковскую цепь.

\subsection{Алгоритм Метрополиса-Гастингса}
Предположим, что нужно промоделировать выборку из распределения $ \pi(dx) $. Идея состоит в построении марковской цепи с инвариантным распределением $ \pi(dx) $. Остановимся на условии детального баланса \eqref{detailed-balance}. Пусть $ f(x) $ --- плотность $ \pi(dx) $, а $ p(x, y) $ --- плотность $ P(x, dy) $. Условие детального баланса тогда эквивалентно соотношению
\begin{equation*}
	f(x) p(x, y) = f(y) p(y, x).
\end{equation*}
Как мы упоминали ранее, из условия детального баланса вытекает условие баланса. Пусть $ X_t $ --- состояние цепи на шаге $ t.$ Алгоритм Метрополиса-Гастингса позволяет построить марковскую цепь с инвариантным распределением $ \pi(dx) $, удовлетворяющую условию детального баланса. Зададим плотность перехода $ \gamma(y|x) $. Чтобы получить марковскую цепь, удовлетворяющую уравнению детального баланса, введём также вероятность принятия состояния, которое получается из $ \gamma(\cdot | x) $, при имеющемся состоянии $ x $. обозначим её $ \alpha(x, y) $. Тогда получим равенство
\begin{equation*}
  p(x, y) = \gamma(y | x) \cdot \alpha(x, y).
\end{equation*}
При этом уравнение детального баланса имеет вид 
\begin{equation}\label{detailed_balance_mh}
	f(x) \cdot \gamma(y | x) \cdot \alpha(x, y) = f(y) \cdot \gamma(x | y) \cdot \alpha(y, x).
\end{equation}
Нетрудно видеть, что  
\begin{equation*}
	\alpha(x, y) =  \min \left\lbrace 1, \dfrac{f(y) \gamma(x|y)}{f(x) \gamma(y|x)} \right\rbrace
\end{equation*}
является одним из решений данного соотношения. Теперь мы можем записать алгоритм моделирования марковской цепи с инвариантным распределением, имеющим плотность~$ f(x) $.

\begin{algorithm}[H] \label{alg_MH}
	\KwIn{Состояние $ x_t $, плотность $ f $, переходная плотность $ \gamma $}
	\KwOut{Состояние $ x_{t+1} $}
	
	
	Промоделировать $ y \sim \gamma(y|x_t) $ \;
	
	Вычислить $ \alpha = \min \left\lbrace 1, \dfrac{f(y) \gamma(x_t|y)}{f(x_t) \gamma(y|x_t)} \right\rbrace  $ \;
	
	Промоделировать $ \beta \sim Unif(0,1)  $ \;
	
	\eIf{$ \beta < \alpha $}
	{$ X_{t + 1} = Y $\;}
	{$ X_{t + 1} = X_t $\;}
	
	
	\caption{Алгоритм Метрополиса-Гастингса}
\end{algorithm}



\section{Алгоритм Ванга-Ландау}
Пусть для каждого значения $ \xi $ задана некоторая функция $ \score(\xi) $ с дискретным множеством значений. Рассмотрим некоторое распределение $ Q $, имеющее плотность вида 
\begin{equation*}
	q(x) \propto w (\score(x)) \cdot f(x),
\end{equation*}
где $ w $ --- некоторая весовая функция. Заметим, что если $ w(\score(x)) \approx \dfrac{1}{P(\score(\xi) = x)} $, то распределение $ \score(\xi) $ будет близко к равномерному на своём множестве значений. Как мы увидим далее, такое распределение является весьма полезным для решаемой задачи и позволяет эффективно моделировать редкие события. 

В качестве способа оценить весовую функцию рассмотрим алгоритм Ванга-Ландау \cite{iba2014multicanonical}. Он является адаптивным и позволяет построить плотность, для которое распределение $ \score $ близко к равномерному. В начале работы алгоритма веса для всех значений $\score $ одинаковые. Потом при помощи Алгоритма Метрополиса-Гастингса моделируется следующее состояние, вычисляется его $ \score, $ и вес данного состояния уменьшается, после чего дальнейшие состояния моделируются уже с учётом изменений. Процесс продолжается, пока гистограмма повстречавшихся значений не будет близка к плоской (то есть распределение значений $ \score $ близко к равномерному).  Далее $ LC $ --- логарифм константы уменьшения веса, $ LW $ --- логарифмические значения весов, $ H(i) $ количество встретившихся состояний цепи, для которых $ \score = i $. Запишем данную схему в виде Алгоритма \ref{alg_WL}. Заметим что при такой схеме моделирования, вообще говоря, свойство эргодичности не гарантируется, поэтому использовать траекторию, полученную в процессе прохода алгоритма Ванга-Ландау для оценки Монте-Карло по схеме марковской цепи нельзя. Поэтому в дальнейшем мы будем сначала оценивать весовую функцию данным алгоритмом, а потом моделировать цепь с нужным нам инвариантным распределением по Алгоритму \ref{alg_MH}.

\begin{algorithm}[H] \label{alg_WL}
	\KwIn{Множество состояний $ \score() $, число итераций $ K_{max}, $ начальное состояние $ X $}
	\KwOut{Логарифмированные значения весовой функции $ LW $}
	$ LC = 1 $ \;
	\While{$ K < K_{max} $}
	{
		$ H(i) = 0 $ для всех состояний $ \score $ \;
	\While{$ H $ не <<плоская>>}
	{Получить следующее состояние $ x^* $ марковской цепи для $ q(x) = f(x) \exp (LW(\score(x))) $\;
	$  LW(\score(x^*)) =LW(\score(x^*)) - LC $ \;
	$ H(\score(x^*)) = H(\score(x^*)) + 1 $\;
		}
	$ LC = LC/2 $ \;
	$ K = K + 1 $ \;
	}
	\caption{Алгоритм Ванга-Ландау}
\end{algorithm}

\section{Оценка дисперсии}

Кроме самих оценок, нас также интересует их дисперсия. В этом разделе мы приведём теоретические факты, касающиеся дисперсии оценок, а также способам её оценить. Дисперсия оценки \eqref{MC-prob-est} имеет вид
\begin{equation}\label{var:mc}
\sigma^2_{MC} = p(1-p).
\end{equation}
Далее речь пойдет об оценке вероятности некоторого события методом Монте-Карло по схеме марковской цепи. Справедлива следующая теорема.
\begin{theorem}[\cite{liang2011advanced}]
Пусть $ X_n $ --- равномерно эргодическая марковская цепь со стационарным распределением $ \pi(dx) $ с плотностью $ f(x) $, $ h(x) $ --- вещественнозначная функция и $ E_f[h^2(\xi)] < \infty $. Тогда существует $ \sigma_h \in \mathbb{R}$ такое, что 
\begin{equation*}
	\sqrt{n} (\bar{h}_n - E_f[h(\xi)]) \Rightarrow N(0, \sigma_h^2),
\end{equation*}
где $ \bar{h}_n = \dfrac{1}{n} \sum_{i = 1}^{n} h(X_i)$,

\begin{equation*}
	\sigma_h^2 = \mathbb{D}_f (h(X_1)) + 2 \sum_{n = 2}^{\infty} \cov_f \left[ h(X_1), h(X_n) \right].
\end{equation*}

\end{theorem}
В статье \cite{flegal2010batch} авторы предлагают следующий способ оценки $ \sigma_h^2 $. Пусть у нас есть траектория длины $ n $ и скользящее окно размера $ b_n $. Вычислим оценку \eqref{MC-est} для каждого положения окна: $ \bar{h}_j (b_n) = b^{-1}_n \sum_{i = 1}^{b_n} X_{i + j},$ где $ j = 0, \ldots, n - b_n $. Тогда оценкой по методу перекрывающихся средних (overlapping batch means) называется величина

\begin{equation}\label{obm}
	\hat{\sigma}^2_{OBM} = \dfrac{n b_n}{(n - b_n)(n - b_n + 1) } \sum_{j = 0}^{n - b_n} (\bar{h}_j (b_n) - \bar{h}_n)^2
\end{equation}

Для оценки \eqref{obm} справедлива следующая теорема.

\begin{theorem}[\cite{flegal2010batch}] \label{th:obm}
	Пусть марковская цепь $ X $ обладает свойством геометрической эргодичности и имеет инвариантное распределение $ \pi(dx) $ с плотностью $ f(x) $, а $ h $ является борелевской вещественнозначной функцией. При этом $ E_\pi [|h|^{2 + \delta + \epsilon}] < \infty $ для некоторых $ \epsilon > 0 $ и $ \delta > 0. $ Если $ b_n = [n^\nu] $, где $ 3/4 > \nu > (1 + \delta/2)^{-1} $. Тогда оценка \eqref{obm} является сильно состоятельной. 
\end{theorem}

\chapter{Оценка вероятности максимального совпадения строк}
\label{ch:strings}
Теперь рассмотрим конкретную задачу вычисления малой вероятности. Стоит отметить, что для данного примера истинное значение известно заранее.

Имеется конечный алфавит $\Sigma$ размера $n$. Рассмотрим множество строк длины $k$ над этим алфавитом. Зафиксируем строку $S^* \in \Sigma^k$. Пусть на нашем множестве задано распределение $P(dx)$. В рамках данной задачи распределение $P$ положим равномерным. Будем оценивать вероятность максимального совпадения строк: $$p = P(\score(S^*, S) = d_{max}),$$ где $\score(S^*,S) = k - d(S^*,S)$, а $d$ --- некоторая метрика, $S$ --- случайная строка. В качестве метрики возьмём расстояние Хэмминга. 

Нетрудно видеть, что $ p = P(d(S^*, S) = 0) = \dfrac{1}{n^k}. $ Мы оценим данную вероятность двумя способами: методом Монте-Карло по независимой выборке и при помощи существенной выборки, промоделировав марковскую цепь с инвариантным распределением, имеющим плотность, оценённую при помощи алгоритма Ванга-Ландау.


\section{Построение оценок}
Пусть $ n = 4, $ а $ k = 10 $. Тогда $ p \approx 9.5 \cdot 10^{-7}. $ Оценка по независимой выборке имеет вид
\begin{equation}\label{est:mc}
\hat{p}_{MC} = 	\frac{1}{n} \sum_{i=1}^{n} \mathbb{I}_{A} (S_i),
\end{equation}
где $ A $ --- множество строк, на которых достигается максимальное совпадение с $ S^* $.

\subsection{Оценка при помощи существенной выборки}
Рассмотрим распределение $ Q $ с плотностью 
\begin{equation}\label{imp_sample_density}
	q(S) = c \cdot w(\score(S)),
\end{equation}
где $ c $ --- некоторая нормирующая константа. Для начала мы получим оценку весовой функции \eqref{imp_sample_density} при помощи Алгоритма \ref{alg_WL}, и, соответственно, $ \hat{Q} $. Затем промоделируем при помощи Алгоритма \ref{alg_MH} марковскую цепь с инвариантным распределением $ \hat{Q} $. Заметим, что для моделирования состояний цепи нет необходимости знать константу $ c $. Вероятность принять состояние $ Y $ выглядит так:
\begin{equation*}
\alpha(X_t, Y) = \min  \left \lbrace 1, \dfrac{q(Y)}{q(X_t)} \right \rbrace.
\end{equation*}
По имеющейся траектории оценка будет выглядеть следующим образом:
\begin{equation*} 
\hat{p}_{IS} = \frac{1}{cn} \sum_{i=1}^{n} \mathbb{I}_A (S_i)/w(\score(S_i)).
\end{equation*}
Заменим теперь $ c $ на состоятельную оценку и получим 
\begin{equation} \label{est:is}
\hat{p}_{IS} = \dfrac{\sum_{i=1}^{n} \mathbb{I}_A (S_i)/w(\score(S_i))}{\sum_{i=1}^{n} 1/w(\score(S_i))}.
\end{equation}
 Для работы этого метода нужно выбрать переходную плотность $ \gamma. $ При имеющейся строке $ Y $ выберем в ней случайную позицию (вероятности для всех позиций равны), и на место этой позиции запишем случайный равновероятно выбранный символ из алфавита. По полученной траектории вычислим оценку \eqref{est:is}. Схема моделирования траектории приведена в виде Алгоритма \ref{alg_est}.

\begin{algorithm}[H] \label{alg_est}
	\KwIn{Начальное состояние $ S_0 $, длина траектории $ N $, число итераций для алгоритма Ванга-Ландау $ K $, множество состояний $ \score $, переходная плотность $ \gamma $}
	\KwOut{траектория  $ \lbrace S_n \rbrace $}
	$ \hat{q} = \exp ( \text{Wang-Landau} (K, \score, \gamma) )$ \;
	$ i = 1 $ \;
	\While{$ i < N $}
	{
		$ S_{i + 1} = $ MH-Step$ (S_i, \hat{q}, \gamma) $ \;
		$ i = i + 1 $ \;
	}
	
	\caption{Алгоритм моделирования траектории для оценки по методу существенной выборки}
\end{algorithm}
Нетрудно проверить, что для такой переходной плотности будет выполняться уравнение детального баланса. Действительно, в нашем случае $ \gamma(x|y) = \gamma(y|x) $ и уравнение \eqref{detailed_balance_mh}  можно сократить, после чего останется верное равенство. Также вычислим дисперсии оценок. Дисперсия оценки \eqref{est:mc} имеет вид \eqref{var:mc}. Обратим внимание на то, что оценка \eqref{est:is} представляет из себя частное двух случайных величин. Сформулируем утверждение, известное как дельта-метод.

\begin{theorem}[Дельта-метод, \cite{wolter2007introduction}]
	Пусть выполнено 
	\begin{equation*}
		\sqrt{n} (\bar{\xi}_n - \bar{a}) \implies N(\textbf{0}, \Sigma)
	\end{equation*}
	для некоторой последовательности случайных величин. Если $ f $--- гладкое отображение, то тогда будет верно соотношение
	\begin{equation*}
		\sqrt{n} (f(\bar{\xi}_n) - f(\bar{a})) \implies N(\textbf{0}, \nabla_f^{\mathrm{T}}(\bar{a})  \Sigma \nabla_f (\bar{a})).
	\end{equation*}
\end{theorem}
Применительно к оценке \eqref{est:is}, функция $ f: \mathbb{R}^2 \rightarrow \mathbb{R} $ и имеет вид $ f(x, y) = x/y. $ Также величины в числителе и знаменателе являются асимптотически нормальными. Для того чтобы оценить дисперсию, нужно вычислить оценку ковариационной матрицы. Для этого применим оценку \eqref{obm} отдельно для оценки дисперсии числителя $x = \sum_{i=1}^{n} \mathbb{I}_A (S_i)/w(\score(S_i))$  и знаменателя $y = \sum_{i=1}^{n} 1/w(\score(S_i)) $ по имеющейся траектории. Для оценки $ \cov (x, y) $ воспользуемся видоизмененной оценкой \eqref{obm}: вместо суммы квадратов по одному batch'у будем вычислять сумму произведений для числителя и для знаменателя. Дисперсию оценки \eqref{est:is} также можно оценить, запустив несколько независимых траекторий и вычислив выборочную дисперсию.

\subsection{Параллельное темперирование}

Рассмотрим ещё один способ вычислить оценку при помощи существенной выборки. Пусть интересующее нас распределение $ Q $ задано следующим образом: $ q(x)\propto \exp(H(x)) $. Также пусть есть $ n $ марковских цепей $ X^{(1)}, \ldots, X^{(n)} $, не зависящих друг от друга. При этом цепь $ X^{(i)} $ имеет инвариантное распределение $ f_i (x) \propto \exp(\beta_i H(x)). $ Из вида плотности видно, что цепи, соответствующие большим значениям $ \beta_i $, больше <<застревают>> в больших значениях функции $ H(x) $. Поэтому возникает идея иногда обменивать состояния разных цепей, например, чтобы уменьшать дисперсию оценки по марковской цепи, соответствующей $ \beta_1 $, но так, чтобы совместное распределение сохранялось, как если бы обмена не было.  Метод параллельного темперирования состоит в том, что цепи моделируются методом Метрополиса-Гастингса, при этом на каждом шаге происходит попытка обменять состояния у двух случайно выбранных цепей. Подробнее метод изложен в \cite{liang2011advanced}.

\begin{algorithm}[H] \label{alg_PT}
	\KwIn{Состояния $ (X_t^{(1)}, \ldots, X_t^{(n)}) $, значения $\beta_1, \ldots, \beta_n$}
	\KwOut{Состояния $ X_{t+1}^{(1)}, \ldots, X_{t+1}^{(n)} $}
	
	
	Для каждого $ X_{t}^{(i)} $ выполнить шаг Метрополиса-Гастингса \;
	
	Выбрать случайную пару индексов $ (i, j) $ \;
	
	вычислить $ \alpha = \min\left\lbrace 1, \exp(\left[ H(X_{t + 1}^{(i)}) - H(X_{t + 1}^{(j)})\right] \left[ \beta_j - \beta_i \right] ) \right\rbrace   $
	
	Промоделировать $ \gamma \sim Unif(0,1)  $ \;
	
	\eIf{$ \gamma < \alpha $}
	{$ Swap(X_{t + 1}^{(j)}, X_{t + 1}^{(i)}) $\;}
	
	
	\caption{Параллельное темперирование}
\end{algorithm}

\subsection{Численные результаты}
Все используемые алгоритмы были реализованы на языке R. Зафиксируем объем выборки (а также длину траектории марковской цепи) $ N = 10^7 $. Далее приведём значения оценок. Здесь $ \hat{p}_{MC} $ --- оценка по методу Монте-Карло \eqref{MC-prob-est} по независимой выборке из равномерного распределения, $ \hat{p}_{IS} $ --- оценка \eqref{est:is} по траектории, полученной при помощи Алгоритма \ref{alg_est}, $ \hat{p}_{PT} $ --- оценка при помощи параллельного темперирования (Алгоритм \ref{alg_PT}), $ \sigma^2_{MC} $ --- значение \eqref{var:mc},  $ \hat{\sigma}^2_{IS-MS} $ --- оценка дисперсии по нескольким независимым траекториям, $ \hat{\sigma}^2_{PT-OBM} $ --- оценка дисперсии при помощи OBM для параллельного темперирования, $ \hat{\sigma}^2_{IS-OBM} $ --- оценка дисперсии при помощи OBM для $ \hat{p}_{IS} $.
\begin{itemize}
	\item $ \hat{p}_{MC} \approx 10^{-6} $ 
	
	\item $ \hat{p}_{IS} \approx 9.5 \cdot 10^{-7} $
	
	\item $ \hat{p}_{PT} \approx 9.57 \cdot 10^{-7}  $
	
	\item $ \sigma^2_{MC} \approx 9.5 \cdot 10^{-7} $
	
	\item $ \hat{\sigma}^2_{IS-MS} \approx 2.6 \cdot 10^{-9}  $
	
	\item $ \hat{\sigma}^2_{IS-OBM} \approx 1.85 \cdot 10^{-9} $
	
	\item $ \hat{\sigma}^2_{PT-OBM} \approx 2.97 \cdot 10^{-9} $
\end{itemize}

Видно, что дисперсия оценки по методу существенной выборки меньше, чем дисперсия оценки по независимой выборки напрямую из равномерного распределения. 

Теперь рассмотрим асимптотическое поведение оценки \eqref{est:is} c плотностью, оценённой при помощи Алгоритма \ref{alg_WL}. Для начала построим такие оценки для траекторий различной длины. Зафиксируем длину строки $ k = 10 $. на рис. \ref{fig:trace_mse} изображено поведение среднеквадратического отклонения в зависимости от длины траектории. На рисунке \ref{fig:trace_obm-var} изображены оценки дисперсии по методу OBM  $ \hat{\sigma}_{OBM-IS}^2 $ и по нескольким независимым траекториям $ \hat{\sigma}_{MS}^2 $. Видно, что при большой длине траектории оценки ведут себя одинаково.

\begin{figure}[h]
	\begin{center}
		\includegraphics{trace_mse.png}
		\caption{Среднеквадратическое отклонение при различных длинах траектории} \label{fig:trace_mse}
	\end{center}
\end{figure}

\begin{figure}[h]
	\begin{center}
		\includegraphics{trace_obm-var.png}
		\caption{Среднеквадратическое отклонение при различных длинах траектории} \label{fig:trace_obm-var}
	\end{center}
\end{figure}

Теперь пусть $ N = 10^6 $, а $ k = 4, \ldots, 40 $, где $ k $--- длина строки. Для каждого значения $ k $ промоделируем $ 30 $ траекторий и вычислим относительные (поделённые на истинное значение вероятности) смещение, среднеквадратическое отклонение и дисперсию. Результаты изображены на  Рис. \ref{fig:prob_all}. Видно, что среднеквадратическое отклонение растёт при уменьшении значения вероятности, которую мы хотим оценивать. 

\begin{figure}[h]
	\begin{center}
		\includegraphics{prob_all.png}
		\caption{Среднеквадратическое отклонение при различных длинах траектории} \label{fig:prob_all}
	\end{center}
\end{figure}


\chapter{Разработка библиотеки для оценивания малых вероятностей}
\label{ch:implementation}
Напомним, что основной целью данной работы является разработка библиотеки для вычисления вероятностей редких событий. Данная глава посвящена разработке данного фреймворка. Главная проблема состоит в том, что мы хотим избежать хранения пространства состояний в каком-либо виде. Например, как мы видели в рассмотренной в Главе \ref{ch:strings} задаче, пространство состояний растёт экспоненциально с ростом длины строки. На самом деле нам и не нужно его хранить полностью. Нужно только понимать, как из одного состояния моделировать следующее состояние, то есть нужны распределение $ \gamma $ и функция $ \score $. Это позволит в полной мере воспользоваться алгоритмом Ванга-Ландау и оценкой по существенной выборке. 

\section{Обзор существующих библиотек}

Важным инструментом оценивания малых вероятностей является моделирование марковской цепи с заданным стационарным распределением. Здесь мы рассмотрим существующие решения с открытым исходным кодом в области моделирования марковских цепей, чтобы понять, какие из них можно использовать для разработки.

\subsection{Stan}

Stan --- язык, разработанный для вероятностного программирования (см. \cite{Stan}). В основе языка лежит Stan Core Library --- библиотека на языке C++, предоставляющая следующий интерфейс:
\begin{itemize}
	\item полный байесовский вывод с использованием No-U-Turn sampler (NUTS), варианта Гамильтонова Монте-Карло (см. \cite{Homan:2014:NSA:2627435.2638586});
	\item приближенный байесовский вывод с использованием вариационного вывода;
	\item оценки максимального правдоподобия.
\end{itemize} 

Stan Core Library реализована на основе Stan Math Library, в которой реализованы полностью шаблонизированная матричная алгебра, линейная алгебра и библиотека вероятностных функций.

Нас в первую очередь интересует моделирование марковских цепей, которое в Stan реализовано с помощью NUTS. Обычно такой способ моделирования требует непрерывность пространства состояний. Стоит отметить, что есть способ использовать Гамильтоново Монте-Карло для моделирования дискретных случайных величин (см. \cite{nishimura2017discontinuous}). Но для такого метода нужно хранить все пространство состояний целиком, что для нас неприемлемо. Поэтому Stan не очень подходит в качестве вспомогательного инструмента.
Также интерфейс библиотеки доступен в R и Python в виде соответствующих пакетов RStan и PyStan. 


\subsection{PyMC3}

PyMC3 --- библиотека на языке Python, предоставляющая интерфейс байесовских методов, преимущественно с использованием марковских цепей (см. \cite{Salvatier2016}). Основные элементы API:
\begin{itemize}
	\item распределения. Есть возможность работать с дискретными, непрерывными, многомерными распределениями, а также задавать пользовательские распределения;
	\item моделирование. В библиотеке реализованы различные варианты моделирования марковских цепей: NUTS, алгоритм Метрополиса-Гастингса, метод Гиббса и другие шаговые методы;
	\item диагностика сходимости марковской цепи на основе траектории;
	\item построение различных графиков.
\end{itemize}  

Низкоуровневая часть PyMC3 реализована на основе Theano. PyMC3 позволяет задавать полные вероятностные модели, содержащие различные случайные величины и их взаимодействие. В целом, PyMC3 является гибким инструментом для моделирования марковских цепей и их диагностики. За счёт возможности расширять имеющиеся распределения данная библиотека является наиболее подходящей к рассмотренной в Главе \ref{ch:strings} задаче. При этом отметим, что в PyMC3 нет готовых инструментов для работы с марковскими цепями (определенных на дискретном пространстве состояний) в терминах функции $ \score $. Как мы упоминали выше, это существенный момент. Сейчас в PyMC3 нет полностью готовых функций, из которых можно скомпоновать наше решение. Однако данная библиотека пригодна для расширения.
 
\section{Детали реализации}
Библиотеку в целом можно разделить на три основных части: 
\begin{itemize}
	\item пользовательский интерфейс;
	\item инструменты для моделирования траектории марковской цепи;
	\item инструменты для вычисления оценок
\end{itemize}
Здесь мы рассмотрим эти компоненты и опишем их реализацию. 
\subsection{Пользовательская часть}
Сначала опишем компоненты, которые должен задать пользователь:
\begin{itemize}
	\item распределение $ \gamma(y|x) $  в виде некоторой функции \texttt{proposal($ x $)}, которая моделирует потенциально следующее состояние марковской цепи при текущем состоянии $ x $.
	\item целевое распределение $ P $ случайного объекта, для которого мы хотим вычислить вероятность попасть в некоторое множество, например, в виде функции плотности;
	\item функция, вычисляющая $ \score(x) $ для состояния $ x $, так как в основе метода Ванга-Ландау для оценки распределения $ Q $ существенной выборки лежит возможность вычислять значение этой функции. Более того, для марковской цепи, в которой на множестве состояний определён $ \score, $ сама задача оценивания малой вероятности формулируется в терминах $ \score $.
	\item начальное состояние марковской цепи $ x_0 $.

\end{itemize}

Кроме того, состояние должно иметь вид NumPy-массива. Это необходимо для корректного использования средств PyMC3 для моделирования.

Далее опишем подробности реализации: расширение PyMC3 и  также реализацию остальных компонентов для решения задачи оценивания вероятностей редких событий. Расширенная версия PyMC3 представляет собой некоторое ядро, на основе которого реализованы методы Монте-Карло по схеме марковской цепи.
\subsection{Расширение возможностей PyMC3}

Для начала заметим, что PyMC3 работает с распределениями, сосредоточенными на числовых носителях (даже дискретные распределения работают только с множеством целых чисел). В нашем же случае это неприемлемо: задать отображение множества состояний произвольного случайного объекта сводится либо к заданию некой функции, определённой на множестве случайных объектов, либо к кодированию целыми числами каждого объекта. Первый вариант возможен, вообще говоря, не всегда, а второй означает, что мы должны хранить пространство состояний целиком. Поэтому мы решили расширить возможности PyMC3, чтобы получить инструменты, подходящие для решения поставленной задачи.

Центральным звеном PyMC3 является класс \texttt{Model}, который представляет интерфейс для определения вероятностной модели посредством добавления в неё случайных величин. Причем работа с этим классом со стороны пользователя предполагает использование контекстного менеджера в Python, с использованием синтаксической конструкции \texttt{with} (см \cite{pep343}). В контексте вероятностной модели, определяемой таким образом, происходят все действия со случайными величинами: моделирование выборки, байесовский вывод и так далее. 

Другим важным классом объектом для PyMC3 является распределение, реализованное в виде класса \texttt{Distribution} и его наследников. Каждая случайная величина добавляется в модель в виде вызова конструктора класса её распределения. Интерфейс \texttt{Distribution} достаточно просто устроен и требует лишь задать функцию, возвращающую логарифм плотности в точке.
\subsubsection{Theano в PyMC3}
Теперь рассмотрим подробнее детали вероятностной модели в PyMC3. Случайная величина в оригинальной реализации представляет собой \texttt{TensorVariable} из Theano. Theano --- это библиотека для символьных вычислений (\cite{2016arXiv160502688short}). В рамках Theano из переменных и действий между ними составляется граф вычислений. Когда пользователю нужен результат, граф оптимизируется, компилируется в вызываемую функцию, в которую можно подставить значения входов и получить результат. Примерно то же самое происходит со случайными величинами в PyMC3: по мере добавления переменных в модель составляется граф для вычисления логарифма совместной плотности, и в момент, когда нужно получать конкретные значения плотности (например, при моделировании марковской цепи алгоритмом Метрополиса-Гастингса), компилируется функция, которая используется до тех пор, пока  сама модель не меняется. 

\subsubsection{Реализованные расширения PyMC3}

В нашей версии реализован класс \texttt{FreeCatRV}, представляющий собой произвольный случайный объект, а также возможность добавлять такие объекты в вероятностную модель. Данный класс наследуется от \texttt{Variable} из Theano, что позволяет добавлять произвольные Generic-объекты и операции над ними в граф вычислений. В Theano уже реализована возможность задавать произвольную операцию над переменными при помощи функции \texttt{FromFunctionOp(fn)}, где \texttt{fn} --- Python-функция. Таким образом реализовано вычисление $ \score() $ от случайного объекта. Далее, плотность распределения, нужного для оценки по методу существенной выборки, имеет вид $ P(\score(X)) $, а  после вычисления $ \score()  $ мы получаем число, поэтому дальнейшее вычисление $ \log(P) $ сводится к уже тензорным операциям и легко встраивается в уже имеющиеся в PyMC3 операции. На листинге \ref{lst:Op} показано, как при вычислении логарифма плотности используется определение операции Python-функцией.

\label{lst:Op}
\begin{lstlisting}[language=Python, caption=Определение вычисления Score() с помощью \texttt{FromFunctionOp}, label={lst:Op}]
	from theano.compile.ops import FromFunctionOp
	import theano.tensor as tt
	...
	def logp(self, value):
		...
		#value is theano Variable
		#this is custom operation and can be applied to theano Variable
		scoreOp = FromFunctionOp(fn=self.get_score,
								itypes=[theano.gof.generic], 
								otypes=[tt.lscalar], 
								infer_shape=None) 
		scoret = scoreOp(value) #this is theano tensor
		
		return ...
	
\end{lstlisting} 

Также реализован класс \texttt{WeightedScoreDistribution}, представляющий распределение, имеющее плотность вида \eqref{imp_sample_density}. Он наследуется от \texttt{Distribution} из PyMC3 и при помощи конструктора такого распределения мы можем добавить в вероятностную модель наш произвольный случайный объект. Чтобы задать такое распределение, нужно задать веса и $ w(\score) $ и Python-реализацию вычисления $ \score $ состояния. В листинге \ref{lst:dist} продемонстрированы основные элементы этого класса.


\begin{lstlisting}[language=Python, caption=Класс \texttt{WeightedScoreDistribution}, label={lst:dist}]
	class WeightedScoreDistribution(Distribution):
		def __init__(self, scorer, weighting, pfun=None, ...):
			...
			self.scorer = scorer #this is a function of Generic object
			self.weights = theano.shared(weighting)
			self.p = pfun
			...
		def pfun(self, value):
			if self.p is None:
				return np.array(1).astype('float64')
			else:
				return np.array(self.p(value)).astype('float64')
		def get_score(self, value):
			return np.array(int(self.scorer(value)))

		def logp(self, value):
			...
\end{lstlisting}

Далее, для возможности моделирования реализован класс \texttt{GenericCatMetropolis}, принимающий на вход произвольную функцию \texttt{proposal()}, которая моделирует следующее значение и представляет собой переходную плотность. Класс \texttt{GenericCatMetropolis} позволяет использовать алгоритм Метрополиса-Гастингса для моделирования марковской цепи со стационарным распределением \eqref{imp_sample_density} при помощи функции \texttt{sample()}, уже реализованной в PyMC3. Процесс получения траектории продемонстрирован в листинге \ref{lst:sampling}.

\begin{lstlisting}[language=Python, caption=Моделирование траектории марковской цепи , label={lst:sampling}]
	...
	with pm.Model() as model:
		s = pm.WeightedScoreDistribution('S', #variable name 
										scorer=..., #custom score
										weighting=...), #list of weights
										cat=True, #distribution is non-numeric
										default_val=...) 
		trace = pm.sample(draws=100000, cores=1, 
							start={'S':...}, #initial state
							step=pm.GenericCatMetropolis(vars=[s], #step-method
										 proposal=...), #custom proposal
							compute_convergence_checks=False, 
							chains=1, wl_weights=True) #wang-landau is on
	...
\end{lstlisting} 

Также реализована функция \texttt{wang\textunderscore landau()}, которая позволяет оценить весовую функцию $ w(\score) $ алгоритмом \ref{alg_WL}, и соответственно плотность, из которой нужно моделировать, непосредственно перед процессом моделирования. В функции \texttt{wang\textunderscore landau()} используется реализованный ранее класс \texttt{GenericCatMetropolis}.

\subsection{Модуль для оценки вероятностей}


Теперь у нас есть инструмент для моделирования траектории марковской цепи. Здесь мы опишем реализацию модуля для оценок вероятностей  $ P(\score(X) \in A) $. Центральным объектом является класс \texttt{ProbabilityEstimator}.  Конструктор класса принимает следующие параметры:
\begin{itemize}
 	\item \texttt{p}:  функция плотности, определяющая изначальное распределение случайной величины;
 	\item \texttt{scorefun}: функция, возвращающая $ \score $ состояния;
 	\item \texttt{proposal}: плотность распределения $ \gamma(\cdot | x ) $ --- функция, возвращающая потенциально следующее состояние;
 	\item \texttt{default\textunderscore val}: состояние по умолчанию, используется в качестве стартового состояния марковской цепи. Ожидается, что начальное значение будет в виде NumPy-массива. 
 	\item \texttt{save\textunderscore trace}: флаг, означающий, сохранять траекторию из $ \score $ состояний или нет;
 	\item \texttt{initial\textunderscore weights}: начальные веса для целевой плотности распределения;
 	\item \texttt{ n\textunderscore samples}: длина моделируемой траектории. 
 \end{itemize}

Данный класс предоставляет следующий интерфейс: 

\begin{itemize}
	\item \texttt{estimate\textunderscore between(left, right)}: вычислить вероятность  $ P(\score(\xi) \in [left, right)) $ 
	\item \texttt{estimate\textunderscore boolean(bool\textunderscore func)}: вычислить вероятность $ P(\score(\xi) in A), $ где принадлежность множеству $ A $ задается логической функцией \texttt{bool\textunderscore func}.  В результате выполнения этой и предыдущей функций также вычисляется оценка дисперсии при помощи Overlapping Batch Means;
	\item \texttt{confint(gamma)}: возвращает доверительный интервал уровня \texttt{gamma}.
\end{itemize}
Также в классе есть внутренняя функция \texttt{\textunderscore \textunderscore get\textunderscore score\textunderscore trace()}, при помощи которой происходит моделирование марковской цепи. Данная функция использует результаты, описанные в предыдущем разделе. Объект класса \texttt{ProbabilityEstimator} при создании сохраняет параметры задачи, которые задает пользователь, далее, при вызове, например, метода \texttt{estimate\textunderscore between(left, right)} моделируется марковская цепь, оценивается нужная вероятность, а также оценивается дисперсия этой оценки. 

Таким образом, получена реализация всего процесса решения задачи, который представлен в алгоритме \ref{alg_est}. Исходный код данного модуля доступен на Zenodo (\cite{vladislav_strashko_2020_3867194}). В приложении \ref{app:A} рассмотрен пример из главы \ref{ch:strings} вычисления вероятности с использованием всех реализованных ранее компонент. 


\conclusion
В работе выполнена декомпозиция исходной задачи на подзадачи, приведена необходимая теория для их решения, а также на примере конкретной задачи продемонстрированы численные результаты. Показано, что при использовании оценки по методу существенной выборки можно добиться уменьшения дисперсии оценки. Также схожий результат показывает параллельное темперирование. Также численно исследовано и продемонстрировано асимптотическое поведение оценок, как в зависимости от длины траектории, так и от оцениваемой вероятности. 

Также проведён небольшой обзор существующих и пользующихся популярностью фреймворков в области моделирования марковских цепей --- Stan и PyMC3 и приведены общие идеи реализации библиотеки для оценивания малых вероятностей путём адаптации инструментария PyMC3 под возможность использовать метод Ванга-Ландау.

После этого были реализованы основные компоненты, из которых состоит библиотека: инструмены моделирования марковской цепи на произвольном дискретном пространстве состояний, а также средства оценивания вероятности по такой траектории. Кроме того, разработан пользовательский интерфейс, предоставляющий доступ к этим частям. После этого был рассмотрен пример использования данной библиотеки.

\appendix
\chapter{Пример вычисления малой вероятности} \label{app:A}

Здесь продемонстрируем работу библиотеки применительно к примеру, рассмотренному в главе  \ref{ch:strings}, а именно, вычисление вероятности полного совпадения строк по расстоянию Хэмминга.

Для начала импортируем нужные модули:

\begin{lstlisting}[language=Python]
from small_probs.probability import ProbabilityEstimator
from scipy.spatial.distance import hamming
import numpy as np
from scipy.stats import norm
\end{lstlisting} 

Зададим параметры задачи в качестве пользовательских компонент:

\begin{lstlisting}[language=Python]
class string2:
    def __init__(self, length):
		self.n_letters = length
		self.state_fixed = np.array(["A"] * self.n_letters)
		alphabet = frozenset("ATGC")
		self.letters_list = list(alphabet)
		self.proposed = 0
		self.p_l = np.random.choice(a=self.letters_list, 
															size=100000)
		self.propose_positions = np.random.choice(a=self.n_letters, 
															size=100000)

	def score(self, state):
		return self.n_letters - np.sum(state != self.state_fixed)

	def proposal(self, state):
		if (self.proposed == 100000):
			self.p_l = np.random.choice(a=self.letters_list, 
															size=100000)
			self.propose_positions = np.random.choice(a=self.n_letters, 
															size=100000)
			self.proposed = 0
		state[self.propose_positions[self.proposed]] = self.p_l[self.proposed]
		self.proposed += 1
		return state

\end{lstlisting} 

Промоделируем марковскую цепь и вычислим оценку:

\begin{lstlisting}[language=Python]
s2 = string2(10)
ps = ProbabilityEstimator(p=None, scorefun=s2.score, proposal=s2.proposal, 
										default_val=s2.state_fixed, 
										initial_weights=np.array([2] * 11), save_trace=True)
ps.estimate_between(10, 11)
\end{lstlisting}

Выведем получившуюся оценку и доверительный интервал уровня 0.95

\begin{lstlisting}[language=Python]
print("True value: ", 1/4**10)
print("Probability estimation: ", ps.prob)
print("OBM variance estimation: ", ps.var)
print(gamma, " confidence interval for true probability ", 
		ps.confint(0.95))
\end{lstlisting}

Вывод предыдущих строк:

\begin{lstlisting}
True value:  9.5367431640625e-07
Probability estimation:  9.735235035741608e-07
OBM variance estimation:  1.8743340848133425e-09
0.95  confidence interval for true probability
(8.886696456593089e-07, 1.0583773614890127e-06)
\end{lstlisting}

Также можно сохранить траекторию, и, например вывести график $ \score $ состояний.

\begin{lstlisting}
	trace = ps.score_trace
	plt.figure(figsize=(35,10))
	plt.plot(trace[-15000:])
\end{lstlisting}

Траектория изображена на Рисунке \ref{fig:trace}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.33]{trace.png}
		\caption{Траектория из Score состояний} \label{fig:trace}
	\end{center}
\end{figure}


\bibliographystyle{ugost2008}
\bibliography{books}




\end{document}

